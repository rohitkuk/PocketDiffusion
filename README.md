# pocket_diffusion

:pinched_fingers:	 Trying to implement some of the Stable Diffusion Concepts and Architectures


### Todo 
- [ ] Design the Blue print
  - [ ] AutoEncoder - VAE
  - [ ] Text Encoder
  - [ ] UNet Based Model
- [ ] Getting the Basic parts setup
- [ ] Run a Basic Model
- [ ] Find out Dataset to Run on a small model
### In Progress ···

- [ ] 
- [ ] 

### Done ✓

- [x] Creating the Repo



### Functionalities

- [ ] Prompt to Image Generation
- [ ] Image to Image Generation Based on Prompts
- [ ] Textual Inversion
- [ ] Classifier Free Guidance
- [ ] Image Inpainting 
- [ ] Imapge Outpainting 
- [ ] Control Net eventually


"...the **go to** statement should be abolished..." [[1]](#1).

## References

- https://github.com/kjsman/stable-diffusion-pytorch/tree/main
- https://github.com/CompVis/latent-diffusion/tree/main
- https://github.com/bes-dev/stable_diffusion_quantizer.pytorch
- https://github.com/lwb2099/stable_diffusion_pytorch
- https://github.com/mindforge-ai/neat-stable-diffusion-pytorch
- https://github.com/mspronesti/stable-diffusion

## Original Paper
https://arxiv.org/pdf/2112.10752.pdf

